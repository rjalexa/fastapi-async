We want to finalize the plan to add a new /api/v1/tasks/pdfxtract endpoint to submit a newspaper PDF as images to the LLM and have the interpreted JSON as the response following the established workflow of this project that uses Redis and Celery workers with the token bucket, circuit breaker, retries with backoff/jitter, dead letter queue etc.

To do so:

1.  Use the new `prompts/pdfxtract.txt` prompt for this task.
2.  **Create New Schemas**: Define `Article`, `Page`, and `Document` models in `src/api/schemas.py`, create a `PdfTaskCreate` schema, and add `task_type` to `TaskDetail`. 

The following is an example of the returned JSON:
{
  "filename": "giornale_1950-05-12_p1.png",
  "issue_date": "1950-05-12",
  "pages": [
    {
      "page_number": 1,
      "status": "processed",
      "reason": "",
      "articles": [
        {
          "title": "Titolo dell'articolo",
          "subtitle": "Sottotitolo",
          "author": "Mario Rossi",
          "body": "Testo completo dell'articolo senza interruzioni.",
          "topics": ["politica", "Italia", "democrazia"],
          "summary": "Breve riassunto del contenuto dellâ€™articolo."
        }
      ]
    },
    {
      "page_number": 4,
      "status": "skipped",
      "reason": "conversion failed",
      "articles": []
    }
  ]
}

and the matching pydantic class:

from pydantic import BaseModel
from typing import List

class Article(BaseModel):
    title: str = ""
    subtitle: str = ""
    author: str = ""
    body: str
    topics: List[str] = []
    summary: str = ""

class Page(BaseModel):
    page_number: int
    status: str = "processed"  # "processed" or "skipped"
    reason: str = ""
    articles: List[Article]

class NewspaperEdition(BaseModel):
    filename: str
    issue_date: str  # ISO 8601 format
    pages: List[Page]


3.  **Develop API Router**: Create `src/api/routers/pdfxtract.py`.
4.  **Implement Endpoint**: Implement `create_pdf_extraction_task` to handle file uploads.
5.  **Update Task Service**: Modify `create_task` in `src/api/services.py` to accept a `task_type` and the raw file content.
6.  **Enhance Worker**: Update `src/worker/tasks.py` to handle `pdfxtract` tasks, using the image fo the PDF and the new prompt.
7.  **Integrate Router**: Add the `pdfxtract_router` to `src/api/main.py`.
8.  **Add Dependencies**: Add any dependency to convert the PDF to image to `src/worker/pyproject.toml`.
9.  **Update Frontend**: Modify `frontend/src/pages/TasksHistory.tsx` to display the pdfxtract `task_type`.

The PDF could be processed as follows:

1. Convert PDF to Page Images (e.g., PNG)
Use a tool like pdf2image (Python):

from pdf2image import convert_from_path
pages = convert_from_path("newspaper.pdf", dpi=300)

for i, page in enumerate(pages):
    page.save(f"page_{i+1}.png", "PNG")
Choose 300 DPI or higher for better OCR/vision results.

Save each page as a separate PNG file.

2. Feed Each Image to the LLM Separately
In Gemini 2.5 Flash, you would typically upload the image and send it with your analysis prompt for that page only.
Process each page individually in sequence. Then combine the JSON outputs into one aggregated result.

