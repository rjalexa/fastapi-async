# docker-compose.yml
# Common configurations using YAML anchors
x-worker-common: &worker-common
  build:
    context: .
    dockerfile: ./src/worker/Dockerfile
    args:
      UID: 1000
      GID: 1000
  depends_on:
    redis:
      condition: service_healthy
  volumes:
    - ./src/worker:/app
    - ./prompts:/app/prompts
  user: "1000:1000"
  restart: unless-stopped
  deploy:
    resources:
      limits:
        memory: ${WORKER_MEMORY_LIMIT:-512M}
        cpus: "${WORKER_CPU_LIMIT:-1.0}"
      reservations:
        memory: ${WORKER_MEMORY_RESERVATION:-256M}
        cpus: "${WORKER_CPU_RESERVATION:-0.5}"
  tmpfs:
    - /tmp:noexec,nosuid,size=100m
  logging:
    driver: "json-file"
    options:
      max-size: ${WORKER_LOG_MAX_SIZE:-10m}
      max-file: "${WORKER_LOG_MAX_FILES:-3}"
  stop_signal: SIGTERM
  stop_grace_period: ${WORKER_STOP_GRACE_PERIOD:-30s}

x-worker-environment: &worker-environment
  REDIS_URL: ${REDIS_URL}
  CELERY_BROKER_URL: ${CELERY_BROKER_URL}
  CELERY_RESULT_BACKEND: ${CELERY_RESULT_BACKEND}
  C_FORCE_ROOT: 0
  UV_CACHE_DIR: /tmp/uv-cache
  HOME: /home/celery
  PYTHONDONTWRITEBYTECODE: 1
  PYTHONUNBUFFERED: 1

x-worker-full-environment: &worker-full-environment
  <<: *worker-environment
  OPENROUTER_API_KEY: ${OPENROUTER_API_KEY}
  OPENROUTER_BASE_URL: ${OPENROUTER_BASE_URL}
  OPENROUTER_MODEL: ${OPENROUTER_MODEL}
  OPENROUTER_TIMEOUT: ${OPENROUTER_TIMEOUT}
  CELERY_WORKER_CONCURRENCY: ${CELERY_WORKER_CONCURRENCY:-2}
  CELERY_WORKER_PREFETCH_MULTIPLIER: ${CELERY_WORKER_PREFETCH_MULTIPLIER:-1}
  CELERY_WORKER_MAX_TASKS_PER_CHILD: ${WORKER_MAX_TASKS_PER_CHILD:-1000}
  CELERY_WORKER_MAX_MEMORY_PER_CHILD: ${WORKER_MAX_MEMORY_PER_CHILD:-200000}
  CELERY_WORKER_SEND_TASK_EVENTS: ${CELERY_WORKER_SEND_TASK_EVENTS:-true}
  CELERY_TASK_SEND_SENT_EVENT: ${CELERY_TASK_SEND_SENT_EVENT:-true}
  CELERY_WORKER_DISABLE_RATE_LIMITS: ${CELERY_WORKER_DISABLE_RATE_LIMITS:-true}
  CELERY_TASK_TRACK_STARTED: ${CELERY_TASK_TRACK_STARTED:-true}
  CELERY_WORKER_HIJACK_ROOT_LOGGER: false
  CELERY_TASK_TIME_LIMIT: ${CELERY_TASK_TIME_LIMIT:-900}
  CELERY_TASK_SOFT_TIME_LIMIT: ${CELERY_TASK_SOFT_TIME_LIMIT:-600}

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    # RDB snapshotting configuration for development
    # Saves to disk if: 1 key changes in 15min, 10 keys in 5min, or 10000 keys in 1min
    # For production, consider using AOF for better data durability:
    # command: redis-server --appendonly yes
    # Or use both RDB and AOF together:
    # command: redis-server --save 900 1 --save 300 10 --save 60 10000 --appendonly yes
    command: redis-server --save 900 1 --save 300 10 --save 60 10000 --stop-writes-on-bgsave-error no
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

  api:
    build:
      context: .
      dockerfile: ./src/api/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=${REDIS_URL}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL}
      - OPENROUTER_TIMEOUT=${OPENROUTER_TIMEOUT}
      - DEBUG=${DEBUG:-true}
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./src/api:/app
    command: uv run uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  worker:
    <<: *worker-common
    environment: 
      <<: *worker-full-environment
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    deploy:
      replicas: ${WORKER_REPLICAS:-3}
      resources:
        limits:
          memory: ${WORKER_MEMORY_LIMIT:-512M}
          cpus: "${WORKER_CPU_LIMIT:-1.0}"
        reservations:
          memory: ${WORKER_MEMORY_RESERVATION:-256M}
          cpus: "${WORKER_CPU_RESERVATION:-0.5}"
    healthcheck:
      test: ["CMD", "uv", "run", "celery", "-A", "tasks", "inspect", "ping"]
      interval: ${WORKER_HEALTH_CHECK_INTERVAL:-30s}
      timeout: ${WORKER_HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${WORKER_HEALTH_CHECK_RETRIES:-3}
      start_period: ${WORKER_HEALTH_CHECK_START_PERIOD:-60s}
    labels:
      - "com.asynctaskflow.service=worker"
    command: /app/start_worker.sh

  scheduler:
    <<: *worker-common
    environment: 
      <<: *worker-environment
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    healthcheck:
      test: ["CMD", "sh", "-c", "pgrep -f 'celery.*beat' > /dev/null"]
      interval: ${WORKER_HEALTH_CHECK_INTERVAL:-30s}
      timeout: ${WORKER_HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${WORKER_HEALTH_CHECK_RETRIES:-3}
      start_period: ${WORKER_HEALTH_CHECK_START_PERIOD:-60s}
    command: uv run celery -A tasks beat --loglevel=${LOG_LEVEL:-info}
    labels:
      - "com.asynctaskflow.service=scheduler"


  frontend:
    build:
      context: .
      dockerfile: ./frontend/Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - api
    labels:
      - "com.asynctaskflow.service=frontend"

  reset:
    build:
      context: .
      dockerfile: ./src/api/Dockerfile
    environment:
      - REDIS_URL=${REDIS_URL}
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./utils:/app/utils
    working_dir: /app
    entrypoint: ["uv", "run", "python", "utils/reset_redis.py"]
    profiles:
      - tools

  tests:
    build:
      context: .
      dockerfile: ./tests/Dockerfile
    environment:
      - REDIS_URL=${REDIS_URL}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - CELERY_RESULT_BACKEND=${CELERY_RESULT_BACKEND}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL}
      - OPENROUTER_TIMEOUT=${OPENROUTER_TIMEOUT}
      - PYTHONPATH=/app/src
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./htmlcov:/app/htmlcov
    working_dir: /app
    command: ["uv", "run", "python", "-m", "pytest", "-v", "--cov=src", "--cov-report=term-missing", "--cov-report=html"]
    profiles:
      - tools
    labels:
      - "com.asynctaskflow.service=tests"

volumes:
  redis_data:
